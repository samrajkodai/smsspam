# -*- coding: utf-8 -*-
"""sms spam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18g87_9UTihSncuPXc9GyjItGdAd41jjw
"""

import nltk
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
nltk.download('wordnet')
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import pickle
import re
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
from imblearn.combine import SMOTETomek
from imblearn.under_sampling import NearMiss
import matplotlib.pyplot as plt

df=pd.read_csv('spam.csv',engine='python')

df.head()

df.isnull().sum()

df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)

x=df.drop('v1',axis=1)
y=df['v1']

x

y

message=x.copy()

ps=WordNetLemmatizer()
corpus=[]

for i in range(0,len(message)):
  print(i)
  review=re.sub('[^a-zA-Z]',' ',message['v2'][i])
  review=review.lower()
  review=review.split()
  review=[ps.lemmatize(word) for word in review if not word in stopwords.words('english')]
  review=' '.join(review)
  corpus.append(review)

print(corpus)

cv = CountVectorizer(max_features=2500)
X = cv.fit_transform(corpus).toarray()

X

y=y.replace(('spam','ham'),(1,0))

y

"""**Checking under sampling**"""

count=y.value_counts()
count.plot(kind='bar')

"""**Removing Under** **Sampling**"""

# Implementing Oversampling for Handling Imbalanced 
smk = SMOTETomek(random_state=42)
X_res,y_res=smk.fit_sample(X,y)

"""Splitting the dataset"""

x_train,x_test,y_train,y_test=train_test_split(X_res,y_res,test_size=0.3,random_state=0)

"""**Model Building**"""

classifier=RandomForestClassifier()
classifier.fit(x_train,y_train)

y_pred=classifier.predict(x_test)

print(accuracy_score(y_test,y_pred))
print(confusion_matrix(y_test,y_pred))

print(classification_report(y_test,y_pred))

smk

X_res.shape

y_res.shape

"""**Pickel** **load** **and** **dumb**"""

pickle_out=open('predict.pkl','wb')
pickle.dump(classifier,pickle_out)
pickle_out.close()

pickle.dump(cv,open('cv-transform.pkl','wb'))

clas=pickle.load(open('predict.pkl','rb'))
cv=pickle.load(open('cv-transform.pkl','rb'))

def prdict(data):
  data=[data]
  x=cv.transform(data).toarray()
  s=clas.predict(x)
  if s==0:
    return 'not spam'
  else:
    return "spam message"

prdict("you won 50000000")

prdict('thank you for your invitation')

